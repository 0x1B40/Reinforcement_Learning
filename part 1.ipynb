{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9342d8e7-8b1c-47c9-b8e6-f87b7989a01b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nvtci\\Desktop\\Learning DS\\RL\\abcdef\\lib\\site-packages\\gym\\envs\\registration.py:564: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\nvtci\\Desktop\\Learning DS\\RL\\abcdef\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:97: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\nvtci\\Desktop\\Learning DS\\RL\\abcdef\\lib\\site-packages\\gym\\envs\\classic_control\\cartpole.py:168: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "# how this thing looks like when random actions are taken.\n",
    "import gym\n",
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "for _ in range(1000):\n",
    "    env.render()\n",
    "    env.step(env.action_space.sample())\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17826e7a-9fb5-475c-89a8-6920f89142a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nvtci\\Desktop\\Learning DS\\RL\\abcdef\\lib\\site-packages\\torchvision\\transforms\\functional_pil.py:207: DeprecationWarning: BILINEAR is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BILINEAR instead.\n",
      "  def resize(img, size, interpolation=Image.BILINEAR):\n",
      "C:\\Users\\nvtci\\Desktop\\Learning DS\\RL\\abcdef\\lib\\site-packages\\torchvision\\transforms\\functional_pil.py:280: DeprecationWarning: BICUBIC is deprecated and will be removed in Pillow 10 (2023-07-01). Use Resampling.BICUBIC instead.\n",
      "  def perspective(img, perspective_coeffs, interpolation=Image.BICUBIC, fill=None):\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c580998e-a748-4a23-9188-1bbebd376ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython: from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f0964a6-f235-4916-9870-a35814262812",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "    def __init__(self, img_height,img_width):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc1 = nn.Linear(in_features = img_height * img_width * 3, out_features = 24)\n",
    "        self.fc2 = nn.Linear(in_features=24,out_features=32)\n",
    "        self.out = nn.Linear(in_features=32, out_features = 2)\n",
    "        \n",
    "    def forward(self,t):\n",
    "        t = t.flatten(start_dim=1)\n",
    "        t = F.relu(self.fc1(t))\n",
    "        t= F.relu(self.fc2(t))\n",
    "        t = self.out(t)\n",
    "        return t\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3f90a73-02b5-4ff7-b493-addd7ad3db01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# EXperience Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5bcf7fb5-022b-4fc2-9414-e6b05044ce1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Experience = namedtuple('Experience', ('state','action','next_state','reward'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f2e93910-88c9-44b7-a3fe-75730db85e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = Experience(2,3,1,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb85c2ca-dd51-47eb-a868-8a1926ee9c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Experience(state=2, action=3, next_state=1, reward=4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f291e6d-e125-4925-939a-0d1ab0098ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replay Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62306cfb-d9b8-46ee-b828-7b529bd051e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayMemory():\n",
    "    def __init__(self,capacity):\n",
    "        self.capacity = capacity\n",
    "        self.memory = []\n",
    "        self.push_count = 0\n",
    "        \n",
    "        \n",
    "    def push(self,experience):\n",
    "        if len(self.memory) < self.capacity:\n",
    "            self.memory.append(experience)\n",
    "        else:\n",
    "            self.memory[self.push_count % self.capacity] = experience\n",
    "            self.push_count +=1\n",
    "            \n",
    "    def sample(self,batch_size):\n",
    "        return random.sample(self.memory,batch_size)\n",
    "    \n",
    "    def can_provide_sample(self,batch_size):\n",
    "        return len(self.memory) >=batch_size             "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "999eb661-0e93-4c86-9a95-045dcd914fda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exploration Stratergy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e654347-42d1-426d-b9f7-b370ff44e1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EpsilonGreedyStrategy():\n",
    "    def __init__(self,start,end,decay):\n",
    "        self.start = start\n",
    "        self.end = end\n",
    "        self.decay = decay\n",
    "        \n",
    "    def get_exploration_rate(self,current_step):\n",
    "            return self.end + (self.start - self.end) * \\\n",
    "                math.exp(-1. * current_step * self.decay)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89af61a0-53f8-4e4b-8aac-445db58a7e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reinforcement Learning Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c8f3267-81ee-456d-8b66-5fb715ab1a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Agent():\n",
    "    def __init__(self,strategy,num_actions,device):\n",
    "        self.current_step = 0\n",
    "        self.strategy = strategy\n",
    "        self.num_actions = num_actions\n",
    "        self.device = device\n",
    "        \n",
    "    def select_action(self,state,policy_net):\n",
    "        rate = strategy.get_exploration_rate(self.current_step)\n",
    "        self.current_step +=1\n",
    "        \n",
    "        if( rate > random.random()):\n",
    "            action=random.randrange(self.num_actions) # explore\n",
    "            return torch.tensor([action]).to(self.device)\n",
    "        else:\n",
    "            with torch.no_grad(): # turn off gradient tracking...(check out the blog)\n",
    "                return policy_net(state).argmax(dim=1).to(self.device) # exploit  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8dc5a1e-1407-4d65-910e-ad49b6603158",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CartPoleEnvManager():\n",
    "    def __init__(self,device):\n",
    "        self.device = device\n",
    "        self.env = gym.make('CartPole-v0').unwrapped\n",
    "        self.env.reset()\n",
    "        self.current_screen = None\n",
    "        self.done = False\n",
    "        \n",
    "    def reset(self):\n",
    "        self.env.reset()\n",
    "        self.current_screen = None\n",
    "    \n",
    "    def close(self):\n",
    "        self.env.close()\n",
    "        \n",
    "    def render(self, mode='human'):\n",
    "        return self.env.render(mode) \n",
    "    \n",
    "    def num_actions_available(self):\n",
    "        return self.env.action_space.n\n",
    "    \n",
    "    def take_action(self,action):\n",
    "        _, reward, self.done , _ = self.env.step(action.item())\n",
    "        return torch.tensor([reward],device=self.device)\n",
    "    \n",
    "    def just_starting(self):\n",
    "        return self.current_screen is None\n",
    "    \n",
    "    def get_state(self):\n",
    "        if (self.just_starting() or self.done):\n",
    "            self.current_screen = self.get_processed_screen()\n",
    "            black_screen = torch.zeros_like(self.current_screen)\n",
    "            return black_screen\n",
    "        else:\n",
    "            s1 = self.current_screen\n",
    "            s2 = self.get_processed_screen()\n",
    "            self.current_screen = s2\n",
    "            return s2-s1 \n",
    "    def get_screen_height(self):\n",
    "        screen = self.get_processed_screen()\n",
    "        return screen.shape[2]\n",
    "    \n",
    "    def get_screen_width(self):\n",
    "        screen = self.get_processed_screen()\n",
    "        return screen.shape[3]\n",
    "    \n",
    "    def get_processed_screen(self):\n",
    "        screen = self.render('rgb_array').transpose((2,0,1))\n",
    "        screen = self.crop_screen(screen)\n",
    "        return self.transform_screen_data(screen)\n",
    "    \n",
    "    def crop_screen(self,screen):\n",
    "        screen_height = screen.shape[1]\n",
    "        \n",
    "        # strip off  top and bottom\n",
    "        top = int( screen_height * 0.4)\n",
    "        bottom = int(screen_height * 0.8)\n",
    "        screen = screen[:,top:bottom,:]\n",
    "        return screen\n",
    "    \n",
    "    def transform_screen_data(self,screen):\n",
    "        # Convert to float,rescale,convert to tensor\n",
    "        screen = np.ascontiguousarray(screen,dtype=np.float32)/255\n",
    "        screen = torch.from_numpy(screen)\n",
    "        \n",
    "        # Use torchvision package to compose image transforms\n",
    "        resize = T.Compose([ T.ToPILImage(),T.Resize((40,90)),T.ToTensor()]) \n",
    "        \n",
    "        return resize(screen).unsqueeze(0).to(self.device) # add a batch dimen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2192893-d6cf-4430-a736-aec92724274c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Example of non-processed screen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3f84860-83db-4966-897a-2534c6604b1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nvtci\\Desktop\\Learning DS\\RL\\abcdef\\lib\\site-packages\\gym\\envs\\registration.py:564: UserWarning: \u001b[33mWARN: The environment CartPole-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
      "  logger.warn(\n",
      "C:\\Users\\nvtci\\Desktop\\Learning DS\\RL\\abcdef\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:97: UserWarning: \u001b[33mWARN: We recommend you to use a symmetric and normalized Box action space (range=[-1, 1]) https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAEICAYAAAB/Dx7IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAAsTAAALEwEAmpwYAAAbGElEQVR4nO3deZhc1X3m8e+rXSxGCLUVoQVhECF4k3Ab8GN7jMHYQvYzIn4cDMEgExLBDI7h8ZIAM2PD4zBjOzbEJB4MBGLANqCwRBoGjxGCxCEZlgYLoQVMA9JIspaWQCBZIEvq3/xxT8Ol1Ut1VzdVp+v9PE+p7z3n3FvnVFW/unXurS5FBGZmlo9hte6AmZn1jYPbzCwzDm4zs8w4uM3MMuPgNjPLjIPbzCwzDm5rGJKmSwpJI2rdl0YhabWkT9S6H0ONg9vMLDMObuszH7F2zY+LvV0c3HUsvc38mqRlkl6RdIekMaX6P5PUKuklSYskHVqqC0kXSHpO0jZJP5SkHu4rJH1Z0guStkj6a0nDUt0XJf2bpKslbQUul3SQpFsktUlaI+m/drQv9W2VpO2SVko6NpUfKumutN2Lkr5c2uY4SS2SXpW0SdJVqXyMpJ9I2prG8rikianuIEk3Stogab2kv5I0PNUNl/S9NJ4XgE/38nj/ZdrHdknPSjq5tJ/LJD2f6p6QNLX0uF0o6TnguVT2GUlLU1//XdL7SvfR0/gvl7QgPa7bJa2Q1NxDf4+WtDg9/89KOj2VH5HKyo95m6QT0/q5pefmBUnnl/Z5oqR1kv5C0ub0uJ4maY6kX6f9Xtapz3em1+Z2SU9Ken83/R0m6ZL0OG5NYx3f03Ni3YgI3+r0BqwGHgMOBcYDq4ALUt1JwBbgWGA08LfAL0vbBnAvMA6YBrQBs3u4rwAeSvczDfg18Kep7ovAHuDPgRHAWOAWYCFwIDA9tT8vtf8jYD3wQUDAkcBhFAcKTwDfAEYB7wJeAD6Vtvu/wNlp+QDghLR8PvC/gP2A4cAHgHekunuA64D9gXemx+v8VHcB8AwwNY3roTTOEV2M//eBtcChaX06cERa/jrwdGoj4P3AIaXHbXHa/1hgFrAZOD71dV56HkdXMP7LgdeBOWnb/wE80s3ztX/q77npOZmVXg/HpPo/A1amx+wXwPdK234aOCKN5WPATuDYVHdieq6/AYxM+2kDfpae63cDrwGHl/q8G/hcav814EVgZOk1/Im0fBHwCDAlPR7XAbfV+vcsx1vNO+BbD09O8aL/Qmn9u8CP0vKNwHdLdQekX6DpaT2Aj5TqFwCX9HBfQSnYgf8MLEnLXwT+X6luOPC7jpBIZecD/5yWfwFc1MV9HF/eTyq7FPiHtPxL4ApgQqc2fwL8O/C+TuUTgV3A2FLZmcBDaflB0n90af2TdB/cR1IE7ic6QqdU9ywwt4fH7aTS+rXAt7rY/mMVjP9y4IFS3THAa93c7+eBf+1Udh3wzdL6Ior/cJYBo3t47v+p4/miCO7XgOFp/cA0xuNL7Z8ATiv1+ZFS3TBgA/DR0mu4I7hXASeX2k6ieM3u83z41vPNUyX1b2NpeSdFQENxFL6moyIidgBbgcm9bZvegu9It4+W2qwtLa9J99FV3QSKo6s1ndp33PdU4PkuxnIYcGiaQtgmaRtwGUUAA5wHHAU8k6ZDPpPKb6X4z+B2Sb+R9F1JI9P+RgIbSvu7juLIm9T/zmPqUkS0AhdTBNFmSbfrzamn7sbToXwfhwFf7TTGqakvvY0f9n3OxqjrufPDgOM77ess4PdKbW4A3gP8bUTs6iiUdKqkR9K0xzaKI/wJpe22RsTetPxa+rmpVP8ab74O3zL+iGgH1vHW1065z/eU+rsK2Ntp/FYBn0zJ128ofhEAkLQ/cAjFFEWPIuLd3VRNBVak5WnpPt7YrLS8heJI6TCKt+Md7Tvuey3FW/HO1gIvRsSMbvr1HHCmirnyzwJ3SjokIn5LcSR+haTpwH0UR7H3URxxT4iIPV3sckMaU4dpXd1v6f5/BvxM0jso/gP4DnB2aTzLu9u00xivjIgrOzeS9CF6GH8frQX+JSJO6apS0gHA31C8M7tc0l0R8ZKk0cBdwDnAwojYLemfKKZN+uuNxzg9d1N462un3Oc/iYh/q+K+DJ+czNltwLmSZqZfxv8OPBoRq6vY59clHZxOvF0E3NFVo3Q0tgC4UtKBkg4DvgL8JDX5e+Brkj6gwpGpzWPA9nQScGw66fceSR8EkPQFSU3pqG1b2le7pI9Leq+Kk46vUvyn0R4RG4D7ge9Lekc6+XWEpI+lbRcAX5Y0RdLBwCXdDVzS70s6KT2Wr1McVbaXxvMtSTPSeN4n6ZBudnUDcIGk41Pb/SV9WtKBvY2/j+4FjpJ0tqSR6fZBSX+Q6n8AtETEnwL/G/hRKh9FMb/cBuyRdCrFFFI1PiDps+mdwcUU/5k+0kW7H1G8Zg4DkNQkaW6V992QHNyZiogHgP9GcfS0geKI8Iwqd7uQYv5yKcUv+409tP1z4LcUJ9cepjh5dVPq2z8CV6ay7RRzqONT4H8GmElxAmsLRSgelPY5G1ghaQdF8JwREa9RvP2/kyK0VwH/QjF9AsWR4yiKI/+XU7tJqe4GiimWp4Angbt7GM9o4NupTxspplsuTXVXUfwncH/qw40UJyL3EREtFCf0/i71p5XiHAEVjL9iEbGdInDPoDi63UjxDmF0CsPZwH9Kzb8CHCvprLTdl9N4Xgb+mGIuvBoLKebcX6Z4h/LZiNjdRbsfpPu6X9J2inA/vsr7bkhKJwmswUkKYEaa6zWriKTLgSMj4gu17ksj8RG3mVlmBi24Jc1W8aGAVkndzi2amVnfDMpUSTqJ9GvgFIpLgx4HzoyIlT1uaGZmvRqsI+7jgNaIeCEifgfcDvjssZnZABis67gn89YPJayjh7PHEyZMiOnTpw9SV8zM8rN69Wq2bNnS5fX1NfsAjqT5wHyAadOm0dLSUquumJnVnebmbv++2KBNlaznrZ9Ym0KnT/RFxPUR0RwRzU1NTYPUDTOzoWewgvtxYIakwyWNoviQQLUX+ZuZGYM0VRIReyR9ieJTa8OBmyJiRS+bmZlZBQZtjjsi7qP4I0BmZjaA/MlJM7PMOLjNzDLj4DYzy4yD28wsMw5uM7PMOLjNzDLj4DYzy4yD28wsMw5uM7PMOLjNzDLj4DYzy4yD28wsMw5uM7PMOLjNzDLj4DYzy4yD28wsMw5uM7PMOLjNzDLj4DYzy0xV3zkpaTWwHdgL7ImIZknjgTuA6cBq4PSIeLm6bpqZWYeBOOL+eETMjIjmtH4JsCQiZgBL0rqZmQ2QwZgqmQvcnJZvBk4bhPswM2tY1QZ3APdLekLS/FQ2MSI2pOWNwMSuNpQ0X1KLpJa2trYqu2Fm1jiqmuMGPhIR6yW9E1gs6ZlyZUSEpOhqw4i4HrgeoLm5ucs2Zma2r6qOuCNiffq5GbgHOA7YJGkSQPq5udpOmpnZm/od3JL2l3RgxzLwSWA5sAiYl5rNAxZW20kzM3tTNVMlE4F7JHXs52cR8X8kPQ4skHQesAY4vfpumplZh34Hd0S8ALy/i/KtwMnVdMrMzLrnT06amWXGwW1mlhkHt5lZZhzcZmaZcXCbmWXGwW1mlhkHt5lZZhzcZmaZcXCbmWXGwW1mlhkHt5lZZhzcZmaZcXCbmWXGwW1mlhkHt5lZZhzcZmaZcXCbmWXGwW1mlpleg1vSTZI2S1peKhsvabGk59LPg1O5JF0jqVXSMknHDmbnzcwaUSVH3D8GZncquwRYEhEzgCVpHeBUYEa6zQeuHZhumplZh16DOyJ+CbzUqXgucHNavhk4rVR+SxQeAcZJmjRAfTUzM/o/xz0xIjak5Y3AxLQ8GVhbarcule1D0nxJLZJa2tra+tkNM7PGU/XJyYgIIPqx3fUR0RwRzU1NTdV2w8ysYfQ3uDd1TIGkn5tT+XpgaqndlFRmZmYDpL/BvQiYl5bnAQtL5eekq0tOAF4pTamYmdkAGNFbA0m3AScCEyStA74JfBtYIOk8YA1wemp+HzAHaAV2AucOQp/NzBpar8EdEWd2U3VyF20DuLDaTpmZWff8yUkzs8w4uM3MMuPgNjPLjIPbzCwzDm4zs8w4uM3MMuPgNjPLjIPbzCwzDm4zs8w4uM3MMuPgNjPLjIPbzCwzDm4zs8w4uM3MMuPgNjPLjIPbzCwzDm4zs8w4uM3MMtNrcEu6SdJmSctLZZdLWi9pabrNKdVdKqlV0rOSPjVYHTcza1SVHHH/GJjdRfnVETEz3e4DkHQMcAbw7rTN/5Q0fKA6a2ZmFQR3RPwSeKnC/c0Fbo+IXRHxIsW3vR9XRf/MzKyTaua4vyRpWZpKOTiVTQbWltqsS2X7kDRfUouklra2tiq6YWbWWPob3NcCRwAzgQ3A9/u6g4i4PiKaI6K5qampn90wM2s8/QruiNgUEXsjoh24gTenQ9YDU0tNp6QyMzMbIP0KbkmTSqt/CHRccbIIOEPSaEmHAzOAx6rropmZlY3orYGk24ATgQmS1gHfBE6UNBMIYDVwPkBErJC0AFgJ7AEujIi9g9JzM7MG1WtwR8SZXRTf2EP7K4Erq+mUmZl1z5+cNDPLjIPbzCwzDm4zs8w4uM3MMuPgNjPLTK9XlZgNVb/77TZe37Zxn/KR+49j7Ljfq0GPzCrj4LaGFBFsW7OMNf/6k33qmv7go0z/D2fXoFdmlfFUiTWuiFr3wKxfHNzWsAIHt+XJwW2Ny0fclikHtzWuaK91D8z6xcFtDctTJZYrB7c1Lk+VWKYc3NawwsFtmXJwW+NycFumHNzWuBzclikHtzWs8FUllikHtzWoSDez/PQa3JKmSnpI0kpJKyRdlMrHS1os6bn08+BULknXSGqVtEzSsYM9CLP+8MlJy1UlR9x7gK9GxDHACcCFko4BLgGWRMQMYElaBziV4tvdZwDzgWsHvNdmA8HBbZnqNbgjYkNEPJmWtwOrgMnAXODm1Oxm4LS0PBe4JQqPAOMkTRrojptVz8FteerTHLek6cAs4FFgYkRsSFUbgYlpeTKwtrTZulTWeV/zJbVIamlra+trv82q5qkSy1XFwS3pAOAu4OKIeLVcF8VvQJ9+CyLi+ohojojmpqamvmxqVr3AUyWWrYqCW9JIitD+aUTcnYo3dUyBpJ+bU/l6YGpp8ympzKyu+IjbclXJVSUCbgRWRcRVpapFwLy0PA9YWCo/J11dcgLwSmlKxax+OLgtU5V8ddmHgbOBpyUtTWWXAd8GFkg6D1gDnJ7q7gPmAK3ATuDcgeyw2cDxB3AsT70Gd0Q8DKib6pO7aB/AhVX2y2zQearEcuVPTlrjcnBbphzc1qDCR9yWLQe3NS7/kSnLlIPbzCwzDm5rWP6zrpYrB7c1Ls9xW6Yc3NbAHNyWJwe3NSxfVWK5cnBb43JwW6Yc3NawfMRtuXJwW0MK8HXcli0HtzUsH29brhzc1pgioH1v13Xq7m+qmdUHB7c1pIh2dmx6YZ9yaRgHvPOIGvTIrHIObmtMEcTe3fuWSwwbMfLt749ZHzi4zTrzVInVOQe3WWfyr4XVN79CzTpRt1/4ZFYfKvmy4KmSHpK0UtIKSRel8sslrZe0NN3mlLa5VFKrpGclfWowB2A24DxVYnWuki8L3gN8NSKelHQg8ISkxanu6oj4XrmxpGOAM4B3A4cCD0g6KiK6ufbKrL7IwW11rtcj7ojYEBFPpuXtwCpgcg+bzAVuj4hdEfEixbe9HzcQnTUbfPIRt9W9Ps1xS5oOzAIeTUVfkrRM0k2SDk5lk4G1pc3W0XPQm9UZB7fVt4qDW9IBwF3AxRHxKnAtcAQwE9gAfL8vdyxpvqQWSS1tbW192dRsUHmqxOpdRcEtaSRFaP80Iu4GiIhNEbE3iu9/uoE3p0PWA1NLm09JZW8REddHRHNENDc1NVUzBrOB5eC2OlfJVSUCbgRWRcRVpfJJpWZ/CCxPy4uAMySNlnQ4MAN4bOC6bDa45Ou4rc5VclXJh4GzgaclLU1llwFnSppJ8UfWVgPnA0TECkkLgJUUV6Rc6CtKLBt64x+zutVrcEfEw3T9Sr6vh22uBK6sol9mteOpEqtzfk9o1olPTlq9c3Cbdebgtjrn4DbrxEfcVu8c3Gb7cHBbfXNwm72F/Gddre75FWrWiadKrN45uM324eC2+ubgNuvER9xW7xzcZp05uK3OObjNOnNwW51zcJt14qkSq3cObrN9+NfC6lslfx3QLAsRwVNPPcXOnTt7bavYw/Ddu/e5fqS9vZ2lS5cSo9/R6z5GjRrFrFmzGD58eD97bNY/Dm4bMiKCs846i5UrV/badsyoEdz9rc8z4aD93lK+a9cuzjz9dNZv2d7rPiZNmkRrayv77bdfr23NBpKD2xra9j3j+M2uIwmGMWnUC4yKjUTUuldmPXNwW8Patmcia1+dw+vt+wOw7vWjOWr0Ytqd3FbnfBbGGtLeGM6y7SfyevsBFJ+UFLtjDE9v/xi79o6pdffMeuTgtgYl9sTIfUr3xEjafcBtdc7BbQ0qGDtsxz6lY4b9FvwVqVbnKvmW9zGSHpP0lKQVkq5I5YdLelRSq6Q7JI1K5aPTemuqnz7IYzDrs+Hay8wDl3DQiM2IvYh2Dhj+ErMOXMwIvV7r7pn1qJKTk7uAkyJih6SRwMOSfg58Bbg6Im6X9CPgPODa9PPliDhS0hnAd4DP93QHu3fvZuPGjVUNxKy9vZ09e/ZU1Hb3nr38/cIHGDbiEbbsnkyEOGTkb/hndrDjtd9VfH+bNm1i7Nix1XTbrEu7d+/utq6Sb3kPoOM95ch0C+Ak4I9T+c3A5RTBPTctA9wJ/J0kpf10aevWrdx66629dcWsRxHBK6+8UlHbve3Bzx9tTWtL+3V/O3fu5LbbbmPkyH3nys2qtXXr1m7r1EOevtlIGg48ARwJ/BD4a+CRiDgy1U8Ffh4R75G0HJgdEetS3fPA8RGxpdM+5wPzAaZNm/aBNWvW9GNoZm9qb2/nve99b0UfwBkI/gCODabm5mZaWlq6/MM5FZ2cjIi9ETETmAIcBxxdbaci4vqIaI6I5qampmp3Z2bWMPp0VUlEbAMeAj4EjJPUMdUyBVifltcDUwFS/UFA98f8ZmbWJ5VcVdIkaVxaHgucAqyiCPDPpWbzgIVpeVFaJ9U/2NP8tpmZ9U0lV5VMAm5O89zDgAURca+klcDtkv4K+BVwY2p/I3CrpFbgJeCMQei3mVnDquSqkmXArC7KX6CY7+5c/jrwRwPSOzMz24c/OWlmlhn/dUAbUk4++WSOOuqot+W+xo8f7y9RsJpwcNuQMWzYMK655ppad8Ns0HmqxMwsMw5uM7PMOLjNzDLj4DYzy4yD28wsMw5uM7PMOLjNzDLj4DYzy4yD28wsMw5uM7PMOLjNzDLj4DYzy4yD28wsMw5uM7PMOLjNzDJTyZcFj5H0mKSnJK2QdEUq/7GkFyUtTbeZqVySrpHUKmmZpGMHeQxmZg2lki9S2AWcFBE7JI0EHpb081T39Yi4s1P7U4EZ6XY8cG36aWZmA6DXI+4o7EirI9MtethkLnBL2u4RYJykSdV31czMoMI5bknDJS0FNgOLI+LRVHVlmg65WtLoVDYZWFvafF0q67zP+ZJaJLW0tbX1fwRmZg2mouCOiL0RMROYAhwn6T3ApcDRwAeB8cBf9uWOI+L6iGiOiOampqa+9drMrIH16aqSiNgGPATMjogNaTpkF/APwHGp2XpgammzKanMzMwGQCVXlTRJGpeWxwKnAM90zFtLEnAasDxtsgg4J11dcgLwSkRsGIS+m5k1pEquKpkE3CxpOEXQL4iIeyU9KKkJELAUuCC1vw+YA7QCO4FzB7zXZmYNrNfgjohlwKwuyk/qpn0AF1bfNTMz64o/OWlmlhkHt5lZZhzcZmaZcXCbmWXGwW1mlhkHt5lZZhzcZmaZcXCbmWXGwW1mlhkHt5lZZhzcZmaZcXCbmWXGwW1mlhkHt5lZZhzcZmaZcXCbmWXGwW1mlhkHt5lZZhzcZmaZcXCbmWXGwW1mlhkVX8pe405I24Fna92PQTIB2FLrTgyCoTouGLpj87jyclhENHVVMeLt7kk3no2I5lp3YjBIahmKYxuq44KhOzaPa+jwVImZWWYc3GZmmamX4L6+1h0YREN1bEN1XDB0x+ZxDRF1cXLSzMwqVy9H3GZmViEHt5lZZmoe3JJmS3pWUqukS2rdn76SdJOkzZKWl8rGS1os6bn08+BULknXpLEuk3Rs7XreM0lTJT0kaaWkFZIuSuVZj03SGEmPSXoqjeuKVH64pEdT/++QNCqVj07rral+ek0H0AtJwyX9StK9aX2ojGu1pKclLZXUksqyfi1Wo6bBLWk48EPgVOAY4ExJx9SyT/3wY2B2p7JLgCURMQNYktahGOeMdJsPXPs29bE/9gBfjYhjgBOAC9Nzk/vYdgEnRcT7gZnAbEknAN8Bro6II4GXgfNS+/OAl1P51aldPbsIWFVaHyrjAvh4RMwsXbOd+2ux/yKiZjfgQ8AvSuuXApfWsk/9HMd0YHlp/VlgUlqeRPEBI4DrgDO7alfvN2AhcMpQGhuwH/AkcDzFJ+9GpPI3XpfAL4APpeURqZ1q3fduxjOFIsBOAu4FNBTGlfq4GpjQqWzIvBb7eqv1VMlkYG1pfV0qy93EiNiQljcCE9NyluNNb6NnAY8yBMaWphOWApuBxcDzwLaI2JOalPv+xrhS/SvAIW9rhyv3N8BfAO1p/RCGxrgAArhf0hOS5qey7F+L/VUvH3kfsiIiJGV7zaWkA4C7gIsj4lVJb9TlOraI2AvMlDQOuAc4urY9qp6kzwCbI+IJSSfWuDuD4SMRsV7SO4HFkp4pV+b6WuyvWh9xrwemltanpLLcbZI0CSD93JzKsxqvpJEUof3TiLg7FQ+JsQFExDbgIYophHGSOg5kyn1/Y1yp/iBg69vb04p8GPiPklYDt1NMl/yA/McFQESsTz83U/xnexxD6LXYV7UO7seBGenM9yjgDGBRjfs0EBYB89LyPIr54Y7yc9JZ7xOAV0pv9eqKikPrG4FVEXFVqSrrsUlqSkfaSBpLMW+/iiLAP5eadR5Xx3g/BzwYaeK0nkTEpRExJSKmU/wePRgRZ5H5uAAk7S/pwI5l4JPAcjJ/LVal1pPswBzg1xTzjP+l1v3pR/9vAzYAuynm0s6jmCtcAjwHPACMT21FcRXN88DTQHOt+9/DuD5CMa+4DFiabnNyHxvwPuBXaVzLgW+k8ncBjwGtwD8Co1P5mLTemurfVesxVDDGE4F7h8q40hieSrcVHTmR+2uxmps/8m5mlplaT5WYmVkfObjNzDLj4DYzy4yD28wsMw5uM7PMOLjNzDLj4DYzy8z/B1D1nCN9AKLFAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "em = CartPoleEnvManager(device)\n",
    "em.reset()\n",
    "screen = em.render('rgb_array')\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(screen)\n",
    "plt.title('non-processed screen example')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e4bc15-9289-4da3-8b8a-237ebb75b3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nvtci\\Desktop\\Learning DS\\RL\\abcdef\\lib\\site-packages\\torch\\cuda\\__init__.py:104: UserWarning: \n",
      "NVIDIA GeForce RTX 3070 with CUDA capability sm_86 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_37 sm_50 sm_60 sm_61 sm_70 sm_75 compute_37.\n",
      "If you want to use the NVIDIA GeForce RTX 3070 GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(incompatible_device_warn.format(device_name, capability, \" \".join(arch_list), device_name))\n"
     ]
    }
   ],
   "source": [
    "screen = em.get_processed_screen()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(screen.squeeze(0).permute(1,2,0),interpolation='none')\n",
    "plt.title('Processed screen example')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf7c835-2352-41cf-a583-fa05121e8cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Example of starting state\n",
    "\n",
    "for i in range(5):\n",
    "    em.take_action(torch.tensor([1]))\n",
    "screen = em.get_state()\n",
    "\n",
    "screen = em.get_state()\n",
    "plt.figure()\n",
    "plt.imshow(screen.squeeze(0).permute(1,2,0),interpolation='none')\n",
    "plt.title('Processed screen example')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ddf642-4cde-4b7a-a323-7bf6e49d2269",
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of end state\n",
    "em.done = True\n",
    "screen = em.get_state()\n",
    "plt.figure()\n",
    "plt.imshow(screen.squeeze(0).permute(1,2,0), interpolation='none')\n",
    "plt.title('processed screen example')\n",
    "plt.show()\n",
    "em.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e733563-ec2d-4d34-ab1a-f0edf3280560",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot(values,moving_avg_period):\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    plt.title('training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(values)\n",
    "    plt.plot(get_moving_average(moving_avg_period,values))\n",
    "    plt.pause(0.001)\n",
    "    if is_ipython: display.clear_output(wait=True)\n",
    "    \n",
    "def get_moving_average(period,values):\n",
    "    values = torch.tensor(values,dtype=torch.float)\n",
    "    if len(values) >= period:\n",
    "        moving_avg = values.unfold(dimension=0,size=period,step=1) \\\n",
    "        .mean(dim=1).flatten(start_dim=0)\n",
    "        moving_avg = torch.cat((torch.zeros(period-1),moving_avg))\n",
    "        return moving_avg.numpy()\n",
    "    else:\n",
    "        moving_avg = torch.zeros(len(values))\n",
    "        return moving_avg.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1d84f6-bccc-4ff9-b0d6-38b30e26bc02",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
